{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 0
   },
   "source": [
    "# Standdown Exercise\n",
    "\n",
    "The cell below stores the text of a set of famous books in the variable nltk_books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T22:19:39.789623Z",
     "start_time": "2021-09-28T22:19:39.776366Z"
    }
   },
   "outputs": [],
   "source": [
    "# nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T22:19:40.923094Z",
     "start_time": "2021-09-28T22:19:39.791155Z"
    },
    "index": 1
   },
   "outputs": [],
   "source": [
    "# Run cell with no changes\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# store raw text of books in a list\n",
    "nltk_books = [nltk.corpus.gutenberg.raw(title) \n",
    "                 for title in nltk.corpus.gutenberg.fileids()]\n",
    "\n",
    "# convert list to dataframe with titles as the index.\n",
    "nltk_books = pd.DataFrame(nltk_books, \n",
    "                          index=nltk.corpus.gutenberg.fileids(),\n",
    "                          columns=['raw_text'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 2
   },
   "source": [
    "The next cell below splits the books into a train and test sets.  This is an arbitrary split, but is here to remind you that we fit a vectorizer only on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T22:19:40.938317Z",
     "start_time": "2021-09-28T22:19:40.924623Z"
    },
    "index": 3
   },
   "outputs": [],
   "source": [
    "# Run cell with no changes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(nltk_books, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T22:19:40.953575Z",
     "start_time": "2021-09-28T22:19:40.939847Z"
    },
    "index": 4
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['milton-paradise.txt', 'shakespeare-macbeth.txt',\n",
       "       'shakespeare-hamlet.txt', 'edgeworth-parents.txt', 'austen-sense.txt',\n",
       "       'chesterton-brown.txt', 'whitman-leaves.txt', 'blake-poems.txt',\n",
       "       'melville-moby_dick.txt', 'carroll-alice.txt',\n",
       "       'chesterton-thursday.txt', 'shakespeare-caesar.txt',\n",
       "       'burgess-busterbrown.txt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are the books whose full texts compose the training set\n",
    "train.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 5
   },
   "source": [
    "Your task is to fit a TfidfVectorizer to the training set with the following specifications: max_features is set to 50, stopwords are removed using the nltk english stopwords list.  The other parameters should be the defaults.  \n",
    "\n",
    "**After fitting the vectorizer, find the word with the highest tf-idf score in Moby Dick. Slack out both the word and tf-idf score, as well as your forked repo showing your work.**\n",
    "\n",
    "> Hint: Converting the vectorized text into a DataFrame with column names and indices will make your life easier.  Use the following hints to make that happen:  \n",
    ">> 1. The TF-IDF vectorizer returns a sparse matrix.  Chain the toarray() method off the vectorizer, then convert that array into a DataFrame.  \n",
    "\n",
    ">> 2. The fit Tf-Idf object has a method called `get_feature_names()`. Assign the result of that method as the `columns` argument of DataFrame.  \n",
    "\n",
    ">> 3. Pass train.index as the index argument of DataFrame.   \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T22:19:41.383735Z",
     "start_time": "2021-09-28T22:19:40.954575Z"
    }
   },
   "outputs": [],
   "source": [
    "# import stopwords and tfidf, set to the above hyperparameters.\n",
    "# fit_transform using raw_text which are the set columns from above\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=50, stop_words='english')\n",
    "\n",
    "train_vectorized = tfidf.fit_transform(train['raw_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T22:19:41.399093Z",
     "start_time": "2021-09-28T22:19:41.384736Z"
    }
   },
   "outputs": [],
   "source": [
    "# get feature names from columns\n",
    "columns = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T22:19:41.414221Z",
     "start_time": "2021-09-28T22:19:41.400114Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a df and set the index\n",
    "train_vect_df = pd.DataFrame(train_vectorized.toarray(), columns=columns)\n",
    "train_vect_df.set_index(train.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T22:19:41.444725Z",
     "start_time": "2021-09-28T22:19:41.415221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>away</th>\n",
       "      <th>came</th>\n",
       "      <th>come</th>\n",
       "      <th>day</th>\n",
       "      <th>did</th>\n",
       "      <th>don</th>\n",
       "      <th>elinor</th>\n",
       "      <th>eyes</th>\n",
       "      <th>father</th>\n",
       "      <th>good</th>\n",
       "      <th>...</th>\n",
       "      <th>thing</th>\n",
       "      <th>think</th>\n",
       "      <th>thou</th>\n",
       "      <th>thought</th>\n",
       "      <th>thy</th>\n",
       "      <th>time</th>\n",
       "      <th>way</th>\n",
       "      <th>whale</th>\n",
       "      <th>world</th>\n",
       "      <th>ye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>milton-paradise.txt</th>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.049906</td>\n",
       "      <td>0.035119</td>\n",
       "      <td>0.110901</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052678</td>\n",
       "      <td>0.057575</td>\n",
       "      <td>0.097039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.533580</td>\n",
       "      <td>0.043436</td>\n",
       "      <td>0.474881</td>\n",
       "      <td>0.037891</td>\n",
       "      <td>0.074858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097039</td>\n",
       "      <td>0.103235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare-macbeth.txt</th>\n",
       "      <td>0.045850</td>\n",
       "      <td>0.020841</td>\n",
       "      <td>0.225080</td>\n",
       "      <td>0.079195</td>\n",
       "      <td>0.175063</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045850</td>\n",
       "      <td>0.071633</td>\n",
       "      <td>0.204240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.501356</td>\n",
       "      <td>0.062522</td>\n",
       "      <td>0.289708</td>\n",
       "      <td>0.191735</td>\n",
       "      <td>0.070859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025009</td>\n",
       "      <td>0.015520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare-hamlet.txt</th>\n",
       "      <td>0.072524</td>\n",
       "      <td>0.021489</td>\n",
       "      <td>0.279353</td>\n",
       "      <td>0.067152</td>\n",
       "      <td>0.169223</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053722</td>\n",
       "      <td>0.144257</td>\n",
       "      <td>0.263236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067152</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.384117</td>\n",
       "      <td>0.037605</td>\n",
       "      <td>0.300048</td>\n",
       "      <td>0.118188</td>\n",
       "      <td>0.029547</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.067152</td>\n",
       "      <td>0.036673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edgeworth-parents.txt</th>\n",
       "      <td>0.054531</td>\n",
       "      <td>0.100045</td>\n",
       "      <td>0.130101</td>\n",
       "      <td>0.116790</td>\n",
       "      <td>0.145129</td>\n",
       "      <td>0.162009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034350</td>\n",
       "      <td>0.129135</td>\n",
       "      <td>0.196225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056678</td>\n",
       "      <td>0.090169</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.135683</td>\n",
       "      <td>0.063548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036926</td>\n",
       "      <td>0.026113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>austen-sense.txt</th>\n",
       "      <td>0.045929</td>\n",
       "      <td>0.036497</td>\n",
       "      <td>0.041828</td>\n",
       "      <td>0.061512</td>\n",
       "      <td>0.101290</td>\n",
       "      <td>0.012215</td>\n",
       "      <td>0.827519</td>\n",
       "      <td>0.022964</td>\n",
       "      <td>0.013214</td>\n",
       "      <td>0.072584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075865</td>\n",
       "      <td>0.086117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098009</td>\n",
       "      <td>0.030346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038137</td>\n",
       "      <td>0.000509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             away      came      come       day       did  \\\n",
       "milton-paradise.txt      0.000924  0.049906  0.035119  0.110901  0.018484   \n",
       "shakespeare-macbeth.txt  0.045850  0.020841  0.225080  0.079195  0.175063   \n",
       "shakespeare-hamlet.txt   0.072524  0.021489  0.279353  0.067152  0.169223   \n",
       "edgeworth-parents.txt    0.054531  0.100045  0.130101  0.116790  0.145129   \n",
       "austen-sense.txt         0.045929  0.036497  0.041828  0.061512  0.101290   \n",
       "\n",
       "                              don    elinor      eyes    father      good  \\\n",
       "milton-paradise.txt      0.000000  0.000000  0.052678  0.057575  0.097039   \n",
       "shakespeare-macbeth.txt  0.020693  0.000000  0.045850  0.071633  0.204240   \n",
       "shakespeare-hamlet.txt   0.003334  0.000000  0.053722  0.144257  0.263236   \n",
       "edgeworth-parents.txt    0.162009  0.000000  0.034350  0.129135  0.196225   \n",
       "austen-sense.txt         0.012215  0.827519  0.022964  0.013214  0.072584   \n",
       "\n",
       "                         ...     thing     think      thou   thought  \\\n",
       "milton-paradise.txt      ...  0.010166  0.021256  0.533580  0.043436   \n",
       "shakespeare-macbeth.txt  ...  0.033345  0.004168  0.501356  0.062522   \n",
       "shakespeare-hamlet.txt   ...  0.067152  0.010744  0.384117  0.037605   \n",
       "edgeworth-parents.txt    ...  0.056678  0.090169  0.001722  0.081152   \n",
       "austen-sense.txt         ...  0.075865  0.086117  0.000000  0.047569   \n",
       "\n",
       "                              thy      time       way     whale     world  \\\n",
       "milton-paradise.txt      0.474881  0.037891  0.074858  0.000000  0.097039   \n",
       "shakespeare-macbeth.txt  0.289708  0.191735  0.070859  0.000000  0.025009   \n",
       "shakespeare-hamlet.txt   0.300048  0.118188  0.029547  0.012102  0.067152   \n",
       "edgeworth-parents.txt    0.002132  0.135683  0.063548  0.000000  0.036926   \n",
       "austen-sense.txt         0.000000  0.098009  0.030346  0.000000  0.038137   \n",
       "\n",
       "                               ye  \n",
       "milton-paradise.txt      0.103235  \n",
       "shakespeare-macbeth.txt  0.015520  \n",
       "shakespeare-hamlet.txt   0.036673  \n",
       "edgeworth-parents.txt    0.026113  \n",
       "austen-sense.txt         0.000509  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick look at the df\n",
    "train_vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T22:19:41.460109Z",
     "start_time": "2021-09-28T22:19:41.446258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "whale    0.835587\n",
       "Name: melville-moby_dick.txt, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find moby dick\n",
    "train_vect_df.loc['melville-moby_dick.txt', :].sort_values(ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T22:19:41.475523Z",
     "start_time": "2021-09-28T22:19:41.462693Z"
    },
    "index": 7
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhale is the highest at 83.5%\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Whale is the highest at 83.5%\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
